# ALPR

An ANPR system identifies the characters and numbers present on the license plate and stores them in a string. This allows the authorities to match the string in the pre-existing database and seamlessly, add a fine to the profile of the violator. ANPR too has its own limitations such as illumination, speed of car, non-uniform license plate and language of number plate. These limitations affect the overall acceptance rate of the system. In this project, we have created an Automatic Number Plate Recognition system.

# Implementation

We have implemented the Automatic License Plate Recognition Software through five major image processing and analytics functions which will be sequentially explained below:

* To begin with, all the five major functions are being called in the main() function. So initially we are calling the loadKNNDataAndTrainKNN() function which is basically responsible for loading the classification.txt and flattened_images.txt file, followed by the training of KNN classifier algorithm. If the files are corrupted or the KNN training fails for some reason the loadKNNDataAndTrainKNN() returns a False value and accordingly the program prints the error message.

* Once the KNN classifier has been trained successfully we read/accept the input license plate image which has to be processed. If the input image is not read properly then the program gives the corresponding error. On successfully accepting the input image we pass the input image to the preprocess() function. 

* In the preprocess() function firstly we are converting the original input image into a grayscale image using cv2.cvtColor function. Then we are using the cv2.GaussianBlur function on the grayscale image in which the image is convolved with a Gaussian filter. The Gaussian filter helps to remove any high frequency component from the image i.e. it smoothens the image. We have found out through certain experimentations that Gaussian filter is the most suitable low pass filter for our image processing requirement. Once the grayscale image has been filtered we apply adaptive thresholding through cv2.adaptiveThreshold function on the filtered image for edge detection and to basically simplify the representation of our original input image into something that is more meaningful and easier to analyse for us. Thus, we are simply implementing segmentation here. After completing the filtering and thresholding operations we are returning the grayscale and thresholded image output back to the main() function where the preprocess() function was called.

* After executing the preprocess() function, we pass imgThreshScene i.e. the thresholded image output to the PossibleCharsInScene() function.

* The main objective of the PossibleCharsInScene() function is to identify all the possible characters present in the thresholded image and store them in a list. Firstly, we are creating an empty list ‘listOfPossibleChars’ which would store the possible characters and we are creating a copy of the thresholded image because the operations used in this function are destructive meaning it manipulates the image that we pass in them. Then we are making use of the cv2.findContours() function to find the contours in the image. A contour basically refers to the outline of an object. So, in the cv2.findContours() function we are passing three parameters. The first parameter is the image whose contours have to be found. The second parameter is cv2.RETR_TREE which tells OpenCV to compute the hierarchy (relationship) between contours. The third parameter is cv2.CV_CHAIN_APPROX_SIMPLE which tells OpenCV to compress the contours in order to save space. The cv2.findContours() function gives us a list of contours that it has found which we are storing in ‘contours’. 

* After obtaining the contours we are traversing through the entire contours list and passing each element of the contours list in the check() function of the PossibleChar class. The check() function is ensuring that if the contours list element satisfies certain conditions that have been laid out by us, it would be appended in the ‘listOfPossibleChars’ list. We are also appending the contours of all the possibleChar which satisfy the check() function into contours which is later used to draw the contours of all the possible characters in the scene with the help of cv2.drawContours function. Finally, we are returning the updated ‘listOfPossibleChars’ list to the main() function where the PossibleCharsInScene() function was called.

* Once the PossibleCharsInScene() function is executed, we are passing ‘listOfPossibleCharsInScene’ i.e. the returned ‘listOfPossibleChars’ list to the ObtainListOfMatchingChars() function.

* In the ObtainListOfMatchingChars() function, firstly we are creating an empty ‘listOfListsOfMatchingChars’ list which would store the list of matching characters present in the image. Now there can be different form of text which could be present in our image but we only want the license plate number text, thus we are trying to match the characters with each other and then cluster all the matching characters in the ‘listOfListsOfMatchingChars’ list. We have laid out conditions which would supervise the matching of characters with each other such that the license plate number text gets clustered into one distinct cluster. Some of the user defined functions which are implementing the above mentioned conditions include distanceBetweenChars() function and angleBetweenChars() function. So in ObtainListOfMatchingChars() function  we have two for loops in which each possibleChar of the ‘listOfPossibleCharsInScene’ list is matched with each character in the ‘listOfPossibleCharsInScene’ list and if a match is found then that character element is appended to the ‘listOfMatchingChars’ list which is an empty list that is created every time we enter the first for loop and it stores the matching characters for the entire first for loop’s iteration. As each first for loop’s iteration gets completed we are appending the updated ‘listOfMatchingChars’ list in the ‘listOfListsOfMatchingChars’ list. Finally, we are returning the updated ‘listOfListsOfMatchingChars’ list to the main() function where ObtainListOfMatchingChars() function was called.

* Now if no matching characters are found in our image, the length of ‘listOfMatchingCharsInPlate’ i.e. the list where the returned ‘listOfListsOfMatchingChars’ is stored, would be zero and accordingly the program will show the message that no characters were found in the license plate number. If the length is not zero then the program is basically traversing each sub-list (‘listOfMatchingChars’) of the list (‘listOfMatchingCharsInPlate’) and for each sub-list all the contours of the characters present in that sub-list are being drawn with the help of cv2.drawContours function.

* Once we are done with drawing the image contours we proceed to the recognition of characters that have been found in the license plate by the machine. So we pass ‘imgThreshScene’ i.e. the thresholded input image and the ‘listOfMatchingChars’ list to the recognizeCharsInPlate() function. 

* In the recognizeCharsInPlate() function we are initially creating an empty string ‘strChars’ which would later store the recognized license plate characters. Then we are traversing the ‘listOfMatchingChars’ list and we are trying to highlight each list element as the Region of Interest (ROI) with the help of cv2.rectangle function followed by its extraction in ‘imgROI’. The ROI is then resized with the help of cv2.resize function and later reshaped through the .reshape function. We are resizing and reshaping the obtained ROI in order to ensure its accurate recognition by the KNN classifier. After resizing and reshaping the ROI we are applying np.float32 conversion on the ‘npaROIResized’ where np.float32 is the single precision float: sign bit, 8 bits exponent, 23 bits mantissa. Once the np.float32 conversion is complete, we are passing the converted ‘npaROIResized’ to the kNearest.findNearest() function with the value of k=5 where k is the number of used nearest neighbours. The kNearest.findNearest() function finds the nearest neighbours of the ‘npaROIResized’ data wrt the trained data and helps to classify the characters accordingly. The output of the kNearest.findNearest() function is being stored in the ‘npaResults’ list which contains the ascii values of all the recognized characters, so we are using the chr() function to convert the ascii values into characters and concatenating these characters in the ‘strChars’ string. Once the entire ‘listOfMatchingChars’ list is traversed we are returning the updated ‘strChars’ string to the main() function where recognizeCharsInPlate() function was called. 

* The return value of recognizeCharsInPlate() function is the license plate number which has been recognized by the machine and is being stored in the ‘final_string’ variable. Finally, we are printing the ‘final_string’ variable which displays the obtained license plate number.
